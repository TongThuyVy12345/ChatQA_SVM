{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN+t8djzhx5yHvi9OtXCUHh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"iMhxUxZoUjLG"},"outputs":[],"source":["import numpy\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from numpy.linalg import norm\n","import csv\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["# Corpus=pd.read_csv('/content/gdrive/MyDrive/NCKH/Data/QA_number_label.csv')\n","# Corpus.head()\n","\n","Answer =[]\n","Question = []\n","with open('/content/gdrive/MyDrive/NCKH/Data/temporary_save.csv', newline='',encoding=\"utf-8\" ) as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        Question.append(row['Question'])\n","        Answer.append(row['Answer'])\n","test1 =input()\n","test =[]\n","test.append(test1)\n","def cosine(x, y):\n","    cos_sim = np.dot(x, y)/(norm(x)*norm(y))\n","    return cos_sim\n","\n","def arrx(arr,n, x):\n","    a = []\n","    for i in range(n):\n","        a.append(arr[x, i])\n","    return a\n","counter = CountVectorizer(min_df=1)\n","tf_matrix = counter.fit_transform(Question)\n","arr = tf_matrix.todense()\n","#mảnh question\n","v = TfidfVectorizer()\n","vectors_train = v.fit_transform(Question)\n","arrv =vectors_train.todense()\n","#Input\n","vt =counter.transform(test).toarray()\n","vy= arrx(vt,len(counter.vocabulary_) ,0)\n","\n","answercorrect =0\n","suitability =0.5\n","for i in range(0, len(Question)):\n","    vx = arrx(arrv,len(counter.vocabulary_) ,i)#chuyển 1 chiều của vector công việc thứ i\n","    # print(suitability(vy, vx))\n","    if suitability(vy,vx) >suitability:\n","        suitability =cosine(vy,vx)\n","        answercorrect=i\n","# print(correct)\n","# print(answer[answercorrect])"],"metadata":{"id":"B_LEtgPEZrnl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from numpy.linalg import norm\n","import csv\n","\n","def cosine(x, y):\n","    cos_sim = np.dot(x, y)/(norm(x)*norm(y))\n","    return cos_sim\n","\n","def arrx(arr,n, x):\n","    a = []\n","    for i in range(n):\n","        a.append(arr[x, i])\n","    return a\n","\n","\n","data =[]\n","answer = []\n","with open('/content/gdrive/MyDrive/NCKH/Data/temporary_save.csv', newline='',encoding=\"utf-8\" ) as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        answer.append(row[\"Answer\"])\n","        data.append(row['Question'])\n","# print(data)\n","# print(congviec)\n","test1 =\"Trầm cảm là gì\"\n","test =[]\n","test.append(test1)\n","\n","\n","# khởi tạo\n","counter = CountVectorizer(min_df=1)\n","# tạo data bằng counter\n","tf_matrix = counter.fit_transform(data)\n","arr = tf_matrix.todense()\n","\n","# khởi tạo\n","v = TfidfVectorizer()\n","# tạo data bằng vectorizen\n","vectors_train = v.fit_transform(data)\n","arrv =vectors_train.todense()\n","\n","# vector hóa dữ liệu test\n","vt =counter.transform(test).toarray()\n","vy= arrx(vt,len(counter.vocabulary_) ,0)#chuyển lại mãng 1 chiều\n","\n","answercorrect =0\n","correct =0.5\n","for i in range(0, len(answer)):\n","    vx = arrx(arrv,len(counter.vocabulary_) ,i)#chuyển 1 chiều của vector công việc thứ i\n","    # print(cosine(vy, vx))\n","    if cosine(vy,vx) >correct:\n","        correct =cosine(vy,vx)\n","        answercorrect=i\n","print(correct)\n","print(answer[answercorrect])\n","# if __name__ == '__main__':\n","#   print(cosine(vy,vx))\n"],"metadata":{"id":"W1JZHfjxvPrz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data =[]\n","answer = []\n","with open('/content/gdrive/MyDrive/NCKH/Data/temporary_save.csv', newline='',encoding=\"utf-8\" ) as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        answer.append(row[\"Answer\"])\n","        data.append(row['Question'])\n","data"],"metadata":{"id":"ANwxBpF9dSY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from numpy.linalg import norm\n","import csv\n","data = []\n","intent=[]\n","rd=pd.read_csv('/content/gdrive/MyDrive/NCKH/Data/Intent-Question-Answer.csv',encoding=\"utf-8\")\n","rd.head()\n"],"metadata":{"id":"KoWYYCt1BHck"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["rd.drop('Intent1',inplace=True,axis=1)\n","rd.Intent.unique()"],"metadata":{"id":"46VI7qDxZw8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["intetion='social-psychology'\n","rd_intent_unique=[intetion]\n","rd_sv=rd[rd.Intent.isin(rd_intent_unique)]\n","rd_sv.to_csv('/content/gdrive/MyDrive/NCKH/Data/temporary_save.csv',encoding=\"utf-8\",index=False)\n","# with open(rd_sv, newline='',encoding=\"utf-8\" ) as csvfile:\n","#     reader = csv.DictReader(csvfile)\n","\n","# for row in reader:\n","#         answer.append(row[\"Answer\"])\n","#         data.append(row['Question'])"],"metadata":{"id":"lE8VVIDQzhWn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n"],"metadata":{"id":"zcKXSw2MaDJq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"wCuUhlYyYHwK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data =[]\n","# answer = []\n","# spamreader = csv.reader(rd_sv,delimiter=' ')\n","# for row in spamreader:\n","#   data=(' '+\"'\".join(Question)+\"'\")\n","#   answer=(' '+\"'\".join(Answer)+\"'\")\n","\n"],"metadata":{"id":"rqkzmsg-vBqo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy\n","import numpy as np\n","import pandas as pd\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from numpy.linalg import norm\n","import csv\n","\n","def cosine(x, y):\n","    cos_sim = np.dot(x, y)/(norm(x)*norm(y))\n","    return cos_sim\n","\n","def arrx(arr,n, x):\n","    a = []\n","    for i in range(n):\n","        a.append(arr[x, i])\n","    return a\n","\n","data =[]\n","answer = []\n","with open('/content/gdrive/MyDrive/NCKH/Data/Intent-Question-Answer.csv', newline='',encoding=\"utf-8\" ) as csvfile:\n","    reader = csv.DictReader(csvfile)\n","    for row in reader:\n","        answer.append(row[\"Answer\"])\n","        data.append(row['Question'])\n","test1 =\"Trầm cảm là gì\"\n","test =[]\n","test.append(test1)\n","\n","\n","# khởi tạo\n","counter = CountVectorizer(min_df=1)\n","# tạo data bằng counter\n","tf_matrix = counter.fit_transform(data)\n","arr = tf_matrix.todense()\n","\n","# khởi tạo\n","v = TfidfVectorizer()\n","# tạo data bằng vectorizen\n","vectors_train = v.fit_transform(data)\n","arrv =vectors_train.todense()\n","\n","# vector hóa dữ liệu test\n","vt =counter.transform(test).toarray()\n","vy= arrx(vt,len(counter.vocabulary_) ,0)#chuyển lại mãng 1 chiều\n","\n","answercorrect =0\n","correct =0.5\n","for i in range(0, len(answer)):\n","    vx = arrx(arrv,len(counter.vocabulary_) ,i)#chuyển 1 chiều của vector công việc thứ i\n","    # print(cosine(vy, vx))\n","    if cosine(vy,vx) >correct:\n","        correct =cosine(vy,vx)\n","        answercorrect=i\n","print(correct)\n","print(answer[answercorrect])"],"metadata":{"id":"3dDcWhO0cudD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# with open('/content/gdrive/MyDrive/NCKH/Data/Intent-Question-Answer.csv', newline='',encoding=\"utf-8\" ) as csvfile:\n","#     reader = csv.DictReader(csvfile)\n","#     for row in reader:\n","#         answer.append(row[\"Answer\"])\n"],"metadata":{"id":"x996nE64l3dw"},"execution_count":null,"outputs":[]}]}