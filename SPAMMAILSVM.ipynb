{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyOyXLyR5l+13Sw32Wo8k8uC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EiG6ZpyCBLvC"},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","from sklearn.model_selection import GridSearchCV\n","from sklearn import svm\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","\n","import string\n","import pickle\n","import pandas as pd\n","nltk.download('all')\n","# initialize the stemmer\n","ps = PorterStemmer()\n","\n","# define the functions\n","def get_importantFeatures(sent):\n","    sent_str = str(sent)\n","    returnList = []\n","    sent_tokens = nltk.word_tokenize(sent_str)\n","    for token in sent_tokens:\n","        if token.isalnum():\n","            returnList.append(token)\n","    return returnList\n","\n","def removing_stopWords(sent):\n","    returnList = []\n","    for i in sent:\n","        if i not in stopwords.words('english') and i not in string.punctuation:\n","            returnList.append(i)\n","    return returnList\n","\n","def potter_stem(sent):\n","    returnList = []\n","    for i in sent:\n","        returnList.append(ps.stem(i))\n","    return \" \".join(returnList)\n","\n","# create the dataframe\n","df = pd.read_csv('/spamCT.csv')\n","\n","\n","# apply the functions to the dataframe\n","df['imp_feature'] = df['EmailText'].apply(get_importantFeatures)\n","df['imp_feature'] = df['imp_feature'].apply(removing_stopWords)\n","df['imp_feature'] = df['imp_feature'].apply(potter_stem)\n","from sklearn.model_selection import train_test_split\n","X = df['imp_feature']\n","y = df['Label']\n","# split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","tfidf = TfidfVectorizer()\n","\n","# convert X_test to a list of strings\n","X_train=X_train.apply(str)\n","y_train=y_train.apply(str)\n","X_test=X_test.apply(str)\n","y_test=y_test.apply(str)\n","\n","# create a TfidfVectorizer object and fit it to the training data\n","feature = tfidf.fit_transform(X_train)\n","\n","# specify the hyperparameters to tune\n","tuned_parameters = {'kernel': ['linear', 'rbf'], 'gamma': [1e-3, 1e-4], 'C': [1, 10, 100, 1000],'probability':'True'}\n","\n","# create a GridSearchCV object and fit it to the training data\n","model = GridSearchCV(svm.SVC(), tuned_parameters)\n","model.fit(feature, y_train)\n","\n","# transform the test data using the fitted TfidfVectorizer object\n","y_predict = tfidf.transform(X_test)\n","print(\"Accuracy:\", model.score(y_predict, y_test))"]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","y_prob = model.predict_proba(tfidf.transform(X_test))[:, 1]\n","roc_auc = roc_auc_score(y_test, y_prob)\n","print(\"ROC AUC Score:\", roc_auc)\n"],"metadata":{"id":"RAmyLfkVQpfS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"PNMIhJh0Bf5I"},"execution_count":null,"outputs":[]}]}